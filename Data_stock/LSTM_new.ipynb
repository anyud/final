{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras_tuner as kt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import os\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "acb_data = pd.read_csv(\"D:\\\\Github anyud\\\\final\\\\Data_stock\\\\ACB_with_MA_and_Diff.csv\")\n",
    "aapl_data = pd.read_csv('D:\\\\Github anyud\\\\final\\\\Data_stock\\\\AAPL_with_MA_and_Diff.csv')\n",
    "bid_data = pd.read_csv('D:\\\\Github anyud\\\\final\\\\Data_stock\\\\BID_with_MA_and_Diff.csv')\n",
    "fpt_data = pd.read_csv('D:\\\\Github anyud\\\\final\\\\Data_stock\\\\FPT_with_MA_and_Diff.csv')\n",
    "googl_data = pd.read_csv('D:\\\\Github anyud\\\\final\\\\Data_stock\\\\GOOGL_with_MA_and_Diff.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL train data points: (1952, 3)\n",
      "ACB train data points: (1944, 3)\n",
      "BID train data points: (1934, 3)\n",
      "FPT train data points: (1934, 3)\n",
      "GOOGL train data points: (1952, 3)\n"
     ]
    }
   ],
   "source": [
    "# Function to split dataset into 80% training and 20% test sets\n",
    "def split_data(df):\n",
    "    train_size = int(len(df) * 0.8)\n",
    "    train_set = df.iloc[:train_size]\n",
    "    test_set = df.iloc[train_size:]\n",
    "    return train_set, test_set\n",
    "\n",
    "# Function to normalize data (excluding date columns)\n",
    "def normalize_data(train, test):\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    # Drop non-numerical columns (e.g., Date column) for normalization\n",
    "    train_numeric = train.drop(columns=['Date'])\n",
    "    test_numeric = test.drop(columns=['Date'])\n",
    "    \n",
    "    # Fit the scaler on the training data and transform both train and test sets\n",
    "    train_scaled = scaler.fit_transform(train_numeric)\n",
    "    test_scaled = scaler.transform(test_numeric)\n",
    "    \n",
    "    return train_scaled, test_scaled\n",
    "\n",
    "# Split each dataset\n",
    "aapl_train, aapl_test = split_data(aapl_data)\n",
    "acb_train, acb_test = split_data(acb_data)\n",
    "bid_train, bid_test = split_data(bid_data)\n",
    "fpt_train, fpt_test = split_data(fpt_data)\n",
    "googl_train, googl_test = split_data(googl_data)\n",
    "\n",
    "# Normalize each dataset\n",
    "aapl_train_scaled, aapl_test_scaled = normalize_data(aapl_train, aapl_test)\n",
    "acb_train_scaled, acb_test_scaled = normalize_data(acb_train, acb_test)\n",
    "bid_train_scaled, bid_test_scaled = normalize_data(bid_train, bid_test)\n",
    "fpt_train_scaled, fpt_test_scaled = normalize_data(fpt_train, fpt_test)\n",
    "googl_train_scaled, googl_test_scaled = normalize_data(googl_train, googl_test)\n",
    "\n",
    "# Print the shape of the normalized datasets to verify\n",
    "print(f\"AAPL train data points: {aapl_train_scaled.shape}\")\n",
    "print(f\"ACB train data points: {acb_train_scaled.shape}\")\n",
    "print(f\"BID train data points: {bid_train_scaled.shape}\")\n",
    "print(f\"FPT train data points: {fpt_train_scaled.shape}\")\n",
    "print(f\"GOOGL train data points: {googl_train_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare sequences for LSTM\n",
    "def create_sequences(data, time_steps=30):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        # Create sequences (input data) using time_steps rows\n",
    "        sequence = data[i:i + time_steps, :]\n",
    "        # Label is the value of 'Price' at the next time step\n",
    "        label = data[i + time_steps, 0]  # Assuming 'Price' is the first column\n",
    "        sequences.append(sequence)\n",
    "        labels.append(label)\n",
    "    return np.array(sequences), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build and train LSTM model and print loss/val_loss per epoch\n",
    "def train_lstm_model(train_sequences, train_labels, stock_name):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, return_sequences=False, input_shape=(train_sequences.shape[1], train_sequences.shape[2])))\n",
    "    model.add(Dense(1))  # Output layer\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    # Train model with validation split (20% of the training data will be used for validation)\n",
    "    history = model.fit(train_sequences, train_labels, epochs=50, batch_size=32, validation_split=0.2, verbose=0)  # verbose=0 to suppress default output\n",
    "    \n",
    "    # Print loss and val_loss for each epoch\n",
    "    for i in range(len(history.history['loss'])):\n",
    "        loss = history.history['loss'][i]\n",
    "        val_loss = history.history['val_loss'][i]\n",
    "        print(f\"Epoch {i+1}: loss = {loss:.6f} - val_loss = {val_loss:.6f}\")\n",
    "    \n",
    "    print(f\"Training complete for {stock_name}\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences for training and testing datasets for each stock\n",
    "aapl_train_sequences, aapl_train_labels = create_sequences(aapl_train_scaled)\n",
    "aapl_test_sequences, aapl_test_labels = create_sequences(aapl_test_scaled)\n",
    "\n",
    "acb_train_sequences, acb_train_labels = create_sequences(acb_train_scaled)\n",
    "acb_test_sequences, acb_test_labels = create_sequences(acb_test_scaled)\n",
    "\n",
    "bid_train_sequences, bid_train_labels = create_sequences(bid_train_scaled)\n",
    "bid_test_sequences, bid_test_labels = create_sequences(bid_test_scaled)\n",
    "\n",
    "fpt_train_sequences, fpt_train_labels = create_sequences(fpt_train_scaled)\n",
    "fpt_test_sequences, fpt_test_labels = create_sequences(fpt_test_scaled)\n",
    "\n",
    "googl_train_sequences, googl_train_labels = create_sequences(googl_train_scaled)\n",
    "googl_test_sequences, googl_test_labels = create_sequences(googl_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss = nan - val_loss = nan\n",
      "Epoch 2: loss = nan - val_loss = nan\n",
      "Epoch 3: loss = nan - val_loss = nan\n",
      "Epoch 4: loss = nan - val_loss = nan\n",
      "Epoch 5: loss = nan - val_loss = nan\n",
      "Epoch 6: loss = nan - val_loss = nan\n",
      "Epoch 7: loss = nan - val_loss = nan\n",
      "Epoch 8: loss = nan - val_loss = nan\n",
      "Epoch 9: loss = nan - val_loss = nan\n",
      "Epoch 10: loss = nan - val_loss = nan\n",
      "Epoch 11: loss = nan - val_loss = nan\n",
      "Epoch 12: loss = nan - val_loss = nan\n",
      "Epoch 13: loss = nan - val_loss = nan\n",
      "Epoch 14: loss = nan - val_loss = nan\n",
      "Epoch 15: loss = nan - val_loss = nan\n",
      "Epoch 16: loss = nan - val_loss = nan\n",
      "Epoch 17: loss = nan - val_loss = nan\n",
      "Epoch 18: loss = nan - val_loss = nan\n",
      "Epoch 19: loss = nan - val_loss = nan\n",
      "Epoch 20: loss = nan - val_loss = nan\n",
      "Epoch 21: loss = nan - val_loss = nan\n",
      "Epoch 22: loss = nan - val_loss = nan\n",
      "Epoch 23: loss = nan - val_loss = nan\n",
      "Epoch 24: loss = nan - val_loss = nan\n",
      "Epoch 25: loss = nan - val_loss = nan\n",
      "Epoch 26: loss = nan - val_loss = nan\n",
      "Epoch 27: loss = nan - val_loss = nan\n",
      "Epoch 28: loss = nan - val_loss = nan\n",
      "Epoch 29: loss = nan - val_loss = nan\n",
      "Epoch 30: loss = nan - val_loss = nan\n",
      "Epoch 31: loss = nan - val_loss = nan\n",
      "Epoch 32: loss = nan - val_loss = nan\n",
      "Epoch 33: loss = nan - val_loss = nan\n",
      "Epoch 34: loss = nan - val_loss = nan\n",
      "Epoch 35: loss = nan - val_loss = nan\n",
      "Epoch 36: loss = nan - val_loss = nan\n",
      "Epoch 37: loss = nan - val_loss = nan\n",
      "Epoch 38: loss = nan - val_loss = nan\n",
      "Epoch 39: loss = nan - val_loss = nan\n",
      "Epoch 40: loss = nan - val_loss = nan\n",
      "Epoch 41: loss = nan - val_loss = nan\n",
      "Epoch 42: loss = nan - val_loss = nan\n",
      "Epoch 43: loss = nan - val_loss = nan\n",
      "Epoch 44: loss = nan - val_loss = nan\n",
      "Epoch 45: loss = nan - val_loss = nan\n",
      "Epoch 46: loss = nan - val_loss = nan\n",
      "Epoch 47: loss = nan - val_loss = nan\n",
      "Epoch 48: loss = nan - val_loss = nan\n",
      "Epoch 49: loss = nan - val_loss = nan\n",
      "Epoch 50: loss = nan - val_loss = nan\n",
      "Training complete for AAPL\n",
      "Epoch 1: loss = nan - val_loss = nan\n",
      "Epoch 2: loss = nan - val_loss = nan\n",
      "Epoch 3: loss = nan - val_loss = nan\n",
      "Epoch 4: loss = nan - val_loss = nan\n",
      "Epoch 5: loss = nan - val_loss = nan\n",
      "Epoch 6: loss = nan - val_loss = nan\n",
      "Epoch 7: loss = nan - val_loss = nan\n",
      "Epoch 8: loss = nan - val_loss = nan\n",
      "Epoch 9: loss = nan - val_loss = nan\n",
      "Epoch 10: loss = nan - val_loss = nan\n",
      "Epoch 11: loss = nan - val_loss = nan\n",
      "Epoch 12: loss = nan - val_loss = nan\n",
      "Epoch 13: loss = nan - val_loss = nan\n",
      "Epoch 14: loss = nan - val_loss = nan\n",
      "Epoch 15: loss = nan - val_loss = nan\n",
      "Epoch 16: loss = nan - val_loss = nan\n",
      "Epoch 17: loss = nan - val_loss = nan\n",
      "Epoch 18: loss = nan - val_loss = nan\n",
      "Epoch 19: loss = nan - val_loss = nan\n",
      "Epoch 20: loss = nan - val_loss = nan\n",
      "Epoch 21: loss = nan - val_loss = nan\n",
      "Epoch 22: loss = nan - val_loss = nan\n",
      "Epoch 23: loss = nan - val_loss = nan\n",
      "Epoch 24: loss = nan - val_loss = nan\n",
      "Epoch 25: loss = nan - val_loss = nan\n",
      "Epoch 26: loss = nan - val_loss = nan\n",
      "Epoch 27: loss = nan - val_loss = nan\n",
      "Epoch 28: loss = nan - val_loss = nan\n",
      "Epoch 29: loss = nan - val_loss = nan\n",
      "Epoch 30: loss = nan - val_loss = nan\n",
      "Epoch 31: loss = nan - val_loss = nan\n",
      "Epoch 32: loss = nan - val_loss = nan\n",
      "Epoch 33: loss = nan - val_loss = nan\n",
      "Epoch 34: loss = nan - val_loss = nan\n",
      "Epoch 35: loss = nan - val_loss = nan\n",
      "Epoch 36: loss = nan - val_loss = nan\n",
      "Epoch 37: loss = nan - val_loss = nan\n",
      "Epoch 38: loss = nan - val_loss = nan\n",
      "Epoch 39: loss = nan - val_loss = nan\n",
      "Epoch 40: loss = nan - val_loss = nan\n",
      "Epoch 41: loss = nan - val_loss = nan\n",
      "Epoch 42: loss = nan - val_loss = nan\n",
      "Epoch 43: loss = nan - val_loss = nan\n",
      "Epoch 44: loss = nan - val_loss = nan\n",
      "Epoch 45: loss = nan - val_loss = nan\n",
      "Epoch 46: loss = nan - val_loss = nan\n",
      "Epoch 47: loss = nan - val_loss = nan\n",
      "Epoch 48: loss = nan - val_loss = nan\n",
      "Epoch 49: loss = nan - val_loss = nan\n",
      "Epoch 50: loss = nan - val_loss = nan\n",
      "Training complete for ACB\n",
      "Epoch 1: loss = nan - val_loss = nan\n",
      "Epoch 2: loss = nan - val_loss = nan\n",
      "Epoch 3: loss = nan - val_loss = nan\n",
      "Epoch 4: loss = nan - val_loss = nan\n",
      "Epoch 5: loss = nan - val_loss = nan\n",
      "Epoch 6: loss = nan - val_loss = nan\n",
      "Epoch 7: loss = nan - val_loss = nan\n",
      "Epoch 8: loss = nan - val_loss = nan\n",
      "Epoch 9: loss = nan - val_loss = nan\n",
      "Epoch 10: loss = nan - val_loss = nan\n",
      "Epoch 11: loss = nan - val_loss = nan\n",
      "Epoch 12: loss = nan - val_loss = nan\n",
      "Epoch 13: loss = nan - val_loss = nan\n",
      "Epoch 14: loss = nan - val_loss = nan\n",
      "Epoch 15: loss = nan - val_loss = nan\n",
      "Epoch 16: loss = nan - val_loss = nan\n",
      "Epoch 17: loss = nan - val_loss = nan\n",
      "Epoch 18: loss = nan - val_loss = nan\n",
      "Epoch 19: loss = nan - val_loss = nan\n",
      "Epoch 20: loss = nan - val_loss = nan\n",
      "Epoch 21: loss = nan - val_loss = nan\n",
      "Epoch 22: loss = nan - val_loss = nan\n",
      "Epoch 23: loss = nan - val_loss = nan\n",
      "Epoch 24: loss = nan - val_loss = nan\n",
      "Epoch 25: loss = nan - val_loss = nan\n",
      "Epoch 26: loss = nan - val_loss = nan\n",
      "Epoch 27: loss = nan - val_loss = nan\n",
      "Epoch 28: loss = nan - val_loss = nan\n",
      "Epoch 29: loss = nan - val_loss = nan\n",
      "Epoch 30: loss = nan - val_loss = nan\n",
      "Epoch 31: loss = nan - val_loss = nan\n",
      "Epoch 32: loss = nan - val_loss = nan\n",
      "Epoch 33: loss = nan - val_loss = nan\n",
      "Epoch 34: loss = nan - val_loss = nan\n",
      "Epoch 35: loss = nan - val_loss = nan\n",
      "Epoch 36: loss = nan - val_loss = nan\n",
      "Epoch 37: loss = nan - val_loss = nan\n",
      "Epoch 38: loss = nan - val_loss = nan\n",
      "Epoch 39: loss = nan - val_loss = nan\n",
      "Epoch 40: loss = nan - val_loss = nan\n",
      "Epoch 41: loss = nan - val_loss = nan\n",
      "Epoch 42: loss = nan - val_loss = nan\n",
      "Epoch 43: loss = nan - val_loss = nan\n",
      "Epoch 44: loss = nan - val_loss = nan\n",
      "Epoch 45: loss = nan - val_loss = nan\n",
      "Epoch 46: loss = nan - val_loss = nan\n",
      "Epoch 47: loss = nan - val_loss = nan\n",
      "Epoch 48: loss = nan - val_loss = nan\n",
      "Epoch 49: loss = nan - val_loss = nan\n",
      "Epoch 50: loss = nan - val_loss = nan\n",
      "Training complete for BID\n",
      "Epoch 1: loss = nan - val_loss = nan\n",
      "Epoch 2: loss = nan - val_loss = nan\n",
      "Epoch 3: loss = nan - val_loss = nan\n",
      "Epoch 4: loss = nan - val_loss = nan\n",
      "Epoch 5: loss = nan - val_loss = nan\n",
      "Epoch 6: loss = nan - val_loss = nan\n",
      "Epoch 7: loss = nan - val_loss = nan\n",
      "Epoch 8: loss = nan - val_loss = nan\n",
      "Epoch 9: loss = nan - val_loss = nan\n",
      "Epoch 10: loss = nan - val_loss = nan\n",
      "Epoch 11: loss = nan - val_loss = nan\n",
      "Epoch 12: loss = nan - val_loss = nan\n",
      "Epoch 13: loss = nan - val_loss = nan\n",
      "Epoch 14: loss = nan - val_loss = nan\n",
      "Epoch 15: loss = nan - val_loss = nan\n",
      "Epoch 16: loss = nan - val_loss = nan\n",
      "Epoch 17: loss = nan - val_loss = nan\n",
      "Epoch 18: loss = nan - val_loss = nan\n",
      "Epoch 19: loss = nan - val_loss = nan\n",
      "Epoch 20: loss = nan - val_loss = nan\n",
      "Epoch 21: loss = nan - val_loss = nan\n",
      "Epoch 22: loss = nan - val_loss = nan\n",
      "Epoch 23: loss = nan - val_loss = nan\n",
      "Epoch 24: loss = nan - val_loss = nan\n",
      "Epoch 25: loss = nan - val_loss = nan\n",
      "Epoch 26: loss = nan - val_loss = nan\n",
      "Epoch 27: loss = nan - val_loss = nan\n",
      "Epoch 28: loss = nan - val_loss = nan\n",
      "Epoch 29: loss = nan - val_loss = nan\n",
      "Epoch 30: loss = nan - val_loss = nan\n",
      "Epoch 31: loss = nan - val_loss = nan\n",
      "Epoch 32: loss = nan - val_loss = nan\n",
      "Epoch 33: loss = nan - val_loss = nan\n",
      "Epoch 34: loss = nan - val_loss = nan\n",
      "Epoch 35: loss = nan - val_loss = nan\n",
      "Epoch 36: loss = nan - val_loss = nan\n",
      "Epoch 37: loss = nan - val_loss = nan\n",
      "Epoch 38: loss = nan - val_loss = nan\n",
      "Epoch 39: loss = nan - val_loss = nan\n",
      "Epoch 40: loss = nan - val_loss = nan\n",
      "Epoch 41: loss = nan - val_loss = nan\n",
      "Epoch 42: loss = nan - val_loss = nan\n",
      "Epoch 43: loss = nan - val_loss = nan\n",
      "Epoch 44: loss = nan - val_loss = nan\n",
      "Epoch 45: loss = nan - val_loss = nan\n",
      "Epoch 46: loss = nan - val_loss = nan\n",
      "Epoch 47: loss = nan - val_loss = nan\n",
      "Epoch 48: loss = nan - val_loss = nan\n",
      "Epoch 49: loss = nan - val_loss = nan\n",
      "Epoch 50: loss = nan - val_loss = nan\n",
      "Training complete for FPT\n",
      "Epoch 1: loss = nan - val_loss = nan\n",
      "Epoch 2: loss = nan - val_loss = nan\n",
      "Epoch 3: loss = nan - val_loss = nan\n",
      "Epoch 4: loss = nan - val_loss = nan\n",
      "Epoch 5: loss = nan - val_loss = nan\n",
      "Epoch 6: loss = nan - val_loss = nan\n",
      "Epoch 7: loss = nan - val_loss = nan\n",
      "Epoch 8: loss = nan - val_loss = nan\n",
      "Epoch 9: loss = nan - val_loss = nan\n",
      "Epoch 10: loss = nan - val_loss = nan\n",
      "Epoch 11: loss = nan - val_loss = nan\n",
      "Epoch 12: loss = nan - val_loss = nan\n",
      "Epoch 13: loss = nan - val_loss = nan\n",
      "Epoch 14: loss = nan - val_loss = nan\n",
      "Epoch 15: loss = nan - val_loss = nan\n",
      "Epoch 16: loss = nan - val_loss = nan\n",
      "Epoch 17: loss = nan - val_loss = nan\n",
      "Epoch 18: loss = nan - val_loss = nan\n",
      "Epoch 19: loss = nan - val_loss = nan\n",
      "Epoch 20: loss = nan - val_loss = nan\n",
      "Epoch 21: loss = nan - val_loss = nan\n",
      "Epoch 22: loss = nan - val_loss = nan\n",
      "Epoch 23: loss = nan - val_loss = nan\n",
      "Epoch 24: loss = nan - val_loss = nan\n",
      "Epoch 25: loss = nan - val_loss = nan\n",
      "Epoch 26: loss = nan - val_loss = nan\n",
      "Epoch 27: loss = nan - val_loss = nan\n",
      "Epoch 28: loss = nan - val_loss = nan\n",
      "Epoch 29: loss = nan - val_loss = nan\n",
      "Epoch 30: loss = nan - val_loss = nan\n",
      "Epoch 31: loss = nan - val_loss = nan\n",
      "Epoch 32: loss = nan - val_loss = nan\n",
      "Epoch 33: loss = nan - val_loss = nan\n",
      "Epoch 34: loss = nan - val_loss = nan\n",
      "Epoch 35: loss = nan - val_loss = nan\n",
      "Epoch 36: loss = nan - val_loss = nan\n",
      "Epoch 37: loss = nan - val_loss = nan\n",
      "Epoch 38: loss = nan - val_loss = nan\n",
      "Epoch 39: loss = nan - val_loss = nan\n",
      "Epoch 40: loss = nan - val_loss = nan\n",
      "Epoch 41: loss = nan - val_loss = nan\n",
      "Epoch 42: loss = nan - val_loss = nan\n",
      "Epoch 43: loss = nan - val_loss = nan\n",
      "Epoch 44: loss = nan - val_loss = nan\n",
      "Epoch 45: loss = nan - val_loss = nan\n",
      "Epoch 46: loss = nan - val_loss = nan\n",
      "Epoch 47: loss = nan - val_loss = nan\n",
      "Epoch 48: loss = nan - val_loss = nan\n",
      "Epoch 49: loss = nan - val_loss = nan\n",
      "Epoch 50: loss = nan - val_loss = nan\n",
      "Training complete for GOOGL\n"
     ]
    }
   ],
   "source": [
    "# Train LSTM models for each stock and display loss/val_loss per epoch\n",
    "aapl_model = train_lstm_model(aapl_train_sequences, aapl_train_labels, \"AAPL\")\n",
    "acb_model = train_lstm_model(acb_train_sequences, acb_train_labels, \"ACB\")\n",
    "bid_model = train_lstm_model(bid_train_sequences, bid_train_labels, \"BID\")\n",
    "fpt_model = train_lstm_model(fpt_train_sequences, fpt_train_labels, \"FPT\")\n",
    "googl_model = train_lstm_model(googl_train_sequences, googl_train_labels, \"GOOGL\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
